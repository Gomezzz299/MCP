# ğŸ§  MCP: Multi-Agent Control Point

Este proyecto implementa un servidor multi-agente que enruta preguntas del usuario a un modelo LLM o a agentes especializados (como fecha, ubicaciÃ³n, clima o un experto tÃ©cnico). Incluye una interfaz web sencilla construida con Streamlit para facilitar su uso.

---

## ğŸš€ CaracterÃ­sticas

- ğŸŒ Backend con FastAPI
- ğŸ§  Agentes especializados (fecha, ubicaciÃ³n, clima, experto LLM)
- ğŸ¤– LÃ³gica inteligente para que los agentes colaboren entre sÃ­
- ğŸ–¥ï¸ Interfaz visual con Streamlit (GUI)
- ğŸ³ Contenedores Docker para fÃ¡cil despliegue
- ğŸ”Œ ComunicaciÃ³n cliente-servidor lista para red local o remoto

---

## ğŸ“ Estructura del proyecto

```
MCP/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ registry.py          # Registra todos los agentes
â”‚   â””â”€â”€ router_llm.py        # Permite distribuciÃ³n entre agentes
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ fecha.py             # Agente de fecha/hora
â”‚   â”œâ”€â”€ ubicacion.py         # Agente de geolocalizaciÃ³n (por IP)
â”‚   â””â”€â”€ clima.py             # Agente de clima (usa ubicaciÃ³n)
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ mcp_server.py        # LÃ³gica del MCP
â”‚   â””â”€â”€ api.py               # Backend FastAPI
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ app.py               # Interfaz Streamlit
â”‚   â””â”€â”€ .streamlit/
â”‚       â””â”€â”€ secrets.toml     # ConfiguraciÃ³n del backend
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ json_parser.py       # FunciÃ³n para dividir json
â”œâ”€â”€ decoradores/
â”‚   â””â”€â”€ utils.py             # Decorador para manejar LLM y respuestas
â”œâ”€â”€ requirements.txt         # Dependencias comunes
â”œâ”€â”€ Dockerfile.backend       # Imagen del backend
â”œâ”€â”€ Dockerfile.frontend      # Imagen del frontend
â””â”€â”€ docker-compose.yml       # OrquestaciÃ³n de servicios
```

---

## âš™ï¸ Requisitos

- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)

---

## ğŸ§ª InstalaciÃ³n rÃ¡pida

### 1. Clona el repositorio

```bash
git clone https://github.com/tu-usuario/MCP.git
cd MCP
```

### 2. Crea archivo de configuraciÃ³n para Streamlit

Dentro del directorio `gui`, crea el archivo:

```
gui/.streamlit/secrets.toml
```

Con el siguiente contenido:

```toml
server_url = "http://backend:8000/process"
```

### 3. Ejecuta con Docker Compose

```bash
docker-compose up --build
```

Esto construirÃ¡ y levantarÃ¡ dos contenedores:

- Backend en `http://localhost:8000`
- Interfaz grÃ¡fica en `http://localhost:8501`

---

## ğŸŒ Acceso desde otra mÃ¡quina (opcional)

1. AsegÃºrate de exponer correctamente los puertos (`8000`, `8501`).
2. Usa la IP de la mÃ¡quina servidor en lugar de `localhost` en `secrets.toml`.
3. TambiÃ©n puedes configurar redes Docker personalizadas para acceso cruzado entre hosts.

---

## ğŸ“¦ Para producciÃ³n

Puedes ejecutar solo el backend si deseas integrarlo con otra interfaz:

```bash
docker build -f Dockerfile.backend -t mcp_backend .
docker run -p 8000:8000 mcp_backend
```

---

## âœ¨ Ejemplo de uso

En la interfaz web, puedes escribir preguntas como:

- `Â¿QuÃ© dÃ­a es hoy?`
- `Â¿DÃ³nde estoy?`
- `Â¿QuÃ© clima hace?`
- `ExplÃ­came quÃ© es Python`

La aplicaciÃ³n decidirÃ¡ si responder directamente o delegar la pregunta a un agente.

---

## ğŸ› ï¸ Agentes disponibles

| Agente       | FunciÃ³n                                 |
|--------------|------------------------------------------|
| FECHA        | Devuelve la fecha y hora actuales        |
| UBICACION    | Detecta la ciudad y paÃ­s mediante IP     |
| CLIMA        | Devuelve el clima en la ubicaciÃ³n actual |

---

## ğŸ”„ InteracciÃ³n entre agentes

El agente de clima ahora usa directamente el agente de ubicaciÃ³n para determinar coordenadas geogrÃ¡ficas (`lat`, `lon`) y ciudad antes de consultar el clima, permitiendo respuestas adaptadas al lugar real del usuario. Esto mejora la modularidad y colaboraciÃ³n entre agentes.

---

## âš ï¸ Notas tÃ©cnicas importantes

- Los agentes devuelven datos estructurados (`dict`) y luego se genera la respuesta natural mediante el decorador @responder_con_llm.

- Los agentes que necesitan datos de otros agentes deben invocar mÃ©todos internos, no los decorados (para evitar recibir solo texto).

- Cada agente especifica quÃ© modelo de LLM utilizar (`llm_simple` o `llm_experto`).

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo MIT License.

---

## ğŸ™‹â€â™‚ï¸ Autor

Desarrollado por Alejandro GÃ³mez Sierra.